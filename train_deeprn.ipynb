{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kutils\n",
    "from kutils.model_helper import ModelHelper\n",
    "from kutils import applications as apps\n",
    "from kutils import image_utils as iu\n",
    "from kutils import tensor_ops as ops\n",
    "from kutils import generic as gen\n",
    "import resnet101\n",
    "\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataset meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_root = '/mnt/home/research/data/'\n",
    "data_root = '/mnt/home/research/koniq/'\n",
    "ids = pd.read_csv(data_root + 'metadata/koniq10k_distributions_sets.csv')\n",
    "\n",
    "# define 5 classes\n",
    "mos_class = np.int32(ids.MOS/20.)\n",
    "ids.loc[:,'class'] = mos_class\n",
    "x = keras.utils.to_categorical(mos_class)\n",
    "classes = pd.DataFrame(x.tolist())\n",
    "output_classes = ['class0', 'class1', 'class2', 'class3', 'class4']\n",
    "classes.columns = output_classes\n",
    "ids = pd.concat([ids, classes], axis=1, verify_integrity=True)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(mos_class),\n",
    "                                                  mos_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepRN base model \n",
    "224x224 crops from 1024x768 + rotation and horizontal flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "loss = categorical_crossentropy\n",
    "data_path = data_root + 'images/1024x768'\n",
    "model_name = 'DeepRN'\n",
    "\n",
    "model = resnet101.resnet101_model(input_shape  = input_shape,\n",
    "                                  weights_root = 'cnn_finetune/imagenet_models', \n",
    "                                  include_top  = True,\n",
    "                                  num_classes  = 5)\n",
    "pre = resnet101.preprocess_input_resnet101\n",
    "\n",
    "# the performance is higher without the rotation augmentation\n",
    "process_fn = lambda im: pre(iu.ImageAugmenter(im, remap=False).crop((224,224)).fliplr().rotate(5).result)\n",
    "\n",
    "gen_params = dict(batch_size    = 64, \n",
    "                  data_path     = data_path, \n",
    "                  fixed_batches = True,\n",
    "                  input_shape   = input_shape, \n",
    "                  process_fn    = process_fn,\n",
    "                  outputs       = output_classes)\n",
    "\n",
    "helper = ModelHelper(model, model_name, ids, verbose = False,\n",
    "                     loss         = categorical_crossentropy, \n",
    "                     optimizer    = keras.optimizers.SGD(lr       = 0.01, \n",
    "                                                         momentum = 0.9, \n",
    "                                                         decay    = 5e-4),\n",
    "                     metrics        = [\"MAE\",'accuracy'], \n",
    "                     monitor_metric = 'val_loss', monitor_mode = 'min',\n",
    "                     early_stop_patience = 20, \n",
    "                     class_weights       = class_weights,\n",
    "                     multiproc    = True, workers = 3,\n",
    "                     logs_root    = aux_root  + 'logs/koniq', \n",
    "                     models_root  = data_root + 'models/', \n",
    "                     gen_params   = gen_params)\n",
    "\n",
    "helper.set_trainable(index=81)\n",
    "print 'First trainable layer:', helper.model.layers[81].name\n",
    "print 'Model name:', helper.model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,_ = helper.test_generator()\n",
    "# iu.view_stack(gen.mapmm(x[0]), figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001 # initial\n",
    "for i in range(3):\n",
    "    print 'Iteration', i\n",
    "    print 'LR =', LR\n",
    "    helper.train(lr=LR, epochs=100)\n",
    "    LR /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.load_model()\n",
    "valid_gen = helper.make_generator(ids[ids.set=='validation'],\n",
    "                                  deterministic=True)\n",
    "print 'Accuracy:', helper.model.evaluate_generator(valid_gen)[2]\n",
    "apps.test_rating_model(helper, groups=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change model to extract features\n",
    "* Huber-loss\n",
    "* allow any resolution input\n",
    "* only horizontal flip augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (768,1024,3)\n",
    "loss = K.tf.losses.huber_loss\n",
    "data_path = data_root + 'images/1024x768/'\n",
    "\n",
    "model = resnet101.resnet101_model(input_shape  = (None, None, 3),\n",
    "                                  weights_root = 'cnn_finetune/imagenet_models', \n",
    "                                  include_top  = False,\n",
    "                                  num_classes  = 5)\n",
    "pre = resnet101.preprocess_input_resnet101\n",
    "process_fn = lambda im: pre(iu.ImageAugmenter(im).fliplr().result)\n",
    "\n",
    "gen_params = dict(batch_size    = 2, \n",
    "                  data_path     = data_path, \n",
    "                  fixed_batches = True,\n",
    "                  input_shape   = input_shape, \n",
    "                  process_fn    = process_fn,\n",
    "                  inputs        = 'image_name',\n",
    "                  outputs       = ('c1','c2','c3','c4','c5'))\n",
    "\n",
    "helper = ModelHelper(model, model_name, ids,\n",
    "                     verbose      = True,                     \n",
    "                     logs_root    = aux_root  + 'logs/koniq', \n",
    "                     models_root  = data_root + 'models/',                     \n",
    "                     features_root= data_root + 'features/',                     \n",
    "                     gen_params   = gen_params)\n",
    "\n",
    "name = 'DeepRN/bsz64_i1[224,224,3]_lcategori_o1[5]'\n",
    "helper.load_model(name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,_ = helper.test_generator()\n",
    "# iu.view_stack(gen.mapmm(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change model head from GAP to SPP\n",
    "(for feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.SpatialPyramidPooling import SpatialPyramidPooling\n",
    "\n",
    "# helper.model.summary()\n",
    "gap_input = helper.model.layers[-2].output\n",
    "feats = SpatialPyramidPooling([3], name='SPP')(gap_input)\n",
    "model_spp = Model(inputs=helper.model.input, outputs=feats)\n",
    "helper.model = model_spp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.save_activations(ids=ids, verbose=True, output_layer='SPP', \n",
    "                        groups=2, over_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (768,1024)\n",
    "input_size = 2048 * 9\n",
    "\n",
    "features_path = data_root + 'features/DeepRN/i1[768,1024,3]_lSPP_o1[2048]_r2.h5'\n",
    "fc1_size = 4096\n",
    "input_feats = keras.layers.Input(shape=(input_size,), dtype='float32')\n",
    "\n",
    "# works better if NOT normalizing the features\n",
    "# norm_feats = Lambda(lambda  x: K.tf.nn.l2_normalize(x,1))(input_feats)\n",
    "\n",
    "pred = apps.fc_layers(input_feats, \n",
    "                     name          = 'main',\n",
    "                     fc_sizes      = [4096,4096,4096, 5], \n",
    "                     dropout_rates = [0.5, 0.5, 0.5,  0],\n",
    "                     batch_norm    = 0,\n",
    "                     out_activation = 'softmax')\n",
    "\n",
    "model = keras.models.Model(inputs=input_feats, outputs=pred)\n",
    "\n",
    "root_name = 'DeepRN_final'\n",
    "\n",
    "gen_params = dict(batch_size  = 128, \n",
    "                  data_path   = features_path,\n",
    "                  process_fn  = None, \n",
    "                  input_shape = (input_size,),\n",
    "                  inputs      = ('image_name',), \n",
    "                  outputs     = ('c1','c2','c3','c4','c5'), \n",
    "                  random_group= True)\n",
    "\n",
    "loss = ops.make_loss(K.tf.losses.huber_loss, delta=1./9)\n",
    "# loss = K.tf.losses.huber_loss\n",
    "\n",
    "helper = ModelHelper(model, root_name, ids, \n",
    "                     loss = loss,\n",
    "                     optimizer = keras.optimizers.SGD(lr       = 0.001, \n",
    "                                                momentum = 0.9, \n",
    "                                                decay    = 4e-4),                     \n",
    "                     metrics=['MAE'], \n",
    "                     monitor_metric='val_loss', monitor_mode='min', \n",
    "                     early_stop_patience = 20, workers = 10,\n",
    "                     logs_root  = aux_root+'/logs/koniq',\n",
    "                     models_root= data_root+'/models',\n",
    "                     gen_params =gen_params)\n",
    "\n",
    "helper.model_name.update(imsz=list(input_shape))\n",
    "print helper.model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "for i in range(4):\n",
    "    print 'Iteration', i\n",
    "    print 'LR =', LR\n",
    "    helper.train(lr=LR, epochs=200)\n",
    "    LR /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.load_model()\n",
    "apps.test_rating_model(helper, groups=2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
